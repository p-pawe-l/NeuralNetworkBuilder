{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342c30e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight array first:  [[0.85973643 0.42974024]\n",
      " [0.59662006 0.82326587]]\n",
      "Weight array second:  [[0.71232259]\n",
      " [0.80551627]]\n",
      "First input:  4.093424862095548\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from typing import Callable, Any\n",
    "\n",
    "\n",
    "class IncorrectArchitectureError(Exception):\n",
    "        pass\n",
    "\n",
    "class IncorrectDatabaseFileFormatError(Exception):\n",
    "        pass\n",
    "\n",
    "class IncorrectNumberOfParametersError(Exception):\n",
    "        pass\n",
    "\n",
    "def ReLu(value):\n",
    "        return np.maximum(0, value)\n",
    "\n",
    "\n",
    "class neural_network:\n",
    "        \"\"\"\n",
    "        neural_network CLASS\n",
    "\n",
    "        Parameters:\n",
    "                architecture: An array containing number of neurons in each layer of created Neural Network\n",
    "                database_file: NPZ type file, which contains data about weights and biases of created Neural Network\n",
    "        \n",
    "        Description:\n",
    "                Purpose of this class is to facilitate creating Neural Network object. \n",
    "                User needs to define an array which describes specific architecture for created Neural Network.\n",
    "                This architercures`s ought to contain number of perceptrons in each layer.\n",
    "                Length of the array is interpreted as number of layers, which newly created Neural Network will contain.\n",
    "                Database file, which is needed for storing data about weights and biases, needs to be provided by user.\n",
    "        \"\"\"\n",
    "        def __init__(self, architecture: list[int], database_file: str) -> None:\n",
    "                # Checking for error connected to providing only one layer\n",
    "                if len(architecture) <= 1:\n",
    "                        raise IncorrectArchitectureError(\"Your neural network must consists of at least 2 layers\")\n",
    "                # This Neural Network builder only manage databases in form of NPZ files\n",
    "                # Providing other others raise and error\n",
    "                if not database_file.endswith(\".npz\"):\n",
    "                        raise IncorrectDatabaseFileFormatError(\"Model of this neural network only works on NPZ files\")\n",
    "\n",
    "                self._architecture: list[int] = architecture\n",
    "                self._database_file: str = database_file\n",
    "                \n",
    "                # Creating empty arrays for paramaters for Neural Network\n",
    "                self._weights_matrices: list[np.ndarray]  = []\n",
    "                self._biases_matrices: list[np.ndarray] = []\n",
    "                self._activation_functons: list[Callable[[np.ndarray], np.ndarray]] = []\n",
    "\n",
    "                number_of_layers: int = len(architecture)\n",
    "                for layer_index in range(number_of_layers - 1):\n",
    "                        # Initializing weights of Neural Network with random numbers from range 0 to 1\n",
    "                        layer_weights_matrix: np.ndarray = np.random.rand(self._architecture[layer_index], self._architecture[layer_index + 1])\n",
    "                        # Initializing biases of Neural Network with zeros\n",
    "                        layer_biases_matrix: np.ndarray = np.zeros((1, self._architecture[layer_index + 1]))\n",
    "\n",
    "                        # Adding newly created matrixes to special arrays\n",
    "                        self._weights_matrices.append(layer_weights_matrix)\n",
    "                        self._biases_matrices.append(layer_biases_matrix)\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        GETTERS METHODS\n",
    "        \"\"\"\n",
    "        @property\n",
    "        def architecture(self) -> list[np.ndarray]:\n",
    "                \"\"\"\n",
    "                Getter of architecture array, which describes structure of Neural Network\n",
    "                \"\"\"\n",
    "                return self._architecture\n",
    "        @property\n",
    "        def weights_matrixes(self) -> list[np.ndarray]:\n",
    "                \"\"\"\n",
    "                Getter for array, which contains weights`s matrixes of each layer in Neural Network\n",
    "                \"\"\"\n",
    "                return self._weights_matrices\n",
    "        @property\n",
    "        def biases_matrixes(self) -> list[np.ndarray]:\n",
    "                \"\"\"\n",
    "                Getter for array, which contains biases`s matries of each layer in Neural Network\n",
    "                \"\"\"\n",
    "                return self._biases_matrices\n",
    "        @property\n",
    "        def activation_functions(self) -> list[Callable[[np.ndarray], np.ndarray]]:\n",
    "                \"\"\"\n",
    "                Getter for array, which contains activation function for neurons in each layer in Neural Network\n",
    "                \"\"\"\n",
    "                return self._activation_functons\n",
    "\n",
    "        \n",
    "        def assign_activation_functions(self, activation_functions: list[Callable[[np.ndarray], np.ndarray]]) -> None:\n",
    "                \"\"\"\n",
    "                Setter method for changing user-provided activation functions\n",
    "\n",
    "                Parameters:\n",
    "                        activation_functions: List of callable functions for each Neural Network`s layer\n",
    "                        Warning: Order of activation functions must correspond to which layer each function is assigned\n",
    "                \"\"\"\n",
    "                # Checking for an error connected to providing incorrect number of activation functions\n",
    "                if len(activation_functions) != (len(self._architecture) - 1):\n",
    "                        raise IncorrectNumberOfParametersError(\"Number of provided activation functions is incorrect\")\n",
    "                \n",
    "                # Assiging new activation functions for Neural Network\n",
    "                self._activation_functons = activation_functions\n",
    "\n",
    "                return None\n",
    "\n",
    "        \n",
    "        def front_propagation(self, input_matrix: np.ndarray, activation_functions: list[Callable[[np.ndarray], np.ndarray]]) -> tuple[np.ndarray, dict[str, Any]]:\n",
    "                \"\"\"\n",
    "                front_propagation METHOD\n",
    "\n",
    "                Parameters:\n",
    "                        input_matrix: Matrix which contains input values for Neural Network\n",
    "                        activation_functions: List of callable functions for each Neural Network`s layer\n",
    "                        Warning: Order of activation functions must correspond to which layer each function is assigned\n",
    "                \n",
    "                Returns:\n",
    "                        current_activations, cache: Tuple of numpy array and dictionary, which conatins pre and post activation values for sums in each layer\n",
    "                \n",
    "                \"\"\"\n",
    "                # Checking if number of activation functions match number of layers in Neural Network\n",
    "                if len(activation_functions) != (len(self._architecture) - 1):\n",
    "                        raise IncorrectNumberOfParametersError(\"Number of activation function is incorrect!\")\n",
    "                # Checking if provided input matrix has proper sizes\n",
    "                if input_matrix.shape[0] != self._architecture[0]:\n",
    "                        raise IncorrectNumberOfParametersError(\"Size of input matrix is incorrect!\")\n",
    "                \n",
    "                current_activations: np.ndarray = input_matrix\n",
    "                # Creating cache with pre and post activation values of sums on each neuron\n",
    "                # This results will be used later in back propagation algorithm \n",
    "                cache: dict[str, Any] = {'A': [input_matrix]}\n",
    "                cache['Z'] = []\n",
    "\n",
    "                # Itterating through Neural Network to achieve correct post actiovation sums on output perceptrons\n",
    "                for layer_index in range(len(self._architecture) - 1):\n",
    "                        # Assigning weights, biases and activation functions to new variable for better readability\n",
    "                        current_weights: np.ndarray = self._weights_matrices[layer_index]\n",
    "                        current_biases: np.ndarray = self._biases_matrices[layer_index]\n",
    "                        current_activation_function: Callable[[np.ndarray], np.ndarray] = activation_functions[layer_index]\n",
    "\n",
    "                        # Calculating pre activation values for sums on each neuron in specific layer with adding proper biases to it\n",
    "                        pre_activation: np.ndarray = current_activations @ current_weights + current_biases\n",
    "                        # Saving result to cache dictionary\n",
    "                        cache['Z'].append(pre_activation)\n",
    "                        \n",
    "                        # Calculating new values for sums after applying provided activation function on them\n",
    "                        post_activation: np.ndarray = current_activation_function(pre_activation)\n",
    "                        # Saving result to cache dictionary\n",
    "                        cache['A'].append(post_activation)\n",
    "\n",
    "                        # Assigning post activtion values of sums to variable with current sums\n",
    "                        current_activations = post_activation\n",
    "\n",
    "                return current_activations, cache\n",
    "        \n",
    "        def predict(self, input_matrix: np.ndarray) -> int:\n",
    "                \"\"\"\n",
    "                predict METHOD\n",
    "\n",
    "                Parameters:\n",
    "                        input_matrix: Matrix which contains input values for Neural Network\n",
    "                \n",
    "                Returns:\n",
    "                        predicted_output_index: Index of perceptron in output array, which Neural Network chooses for being the most activated one\n",
    "                \"\"\"\n",
    "                # Front propagation algorithm in action\n",
    "                final_outputs, _ = self.front_propagation(input_matrix, self._activation_functons)\n",
    "                # Choosing index of most activated value of output matrix\n",
    "                predicited_output_index: int = np.argmax(final_outputs)\n",
    "\n",
    "                return predicited_output_index\n",
    "                \n",
    "                        \n",
    "                        \n",
    "nn: neural_network = neural_network([2, 2, 1], \"xd.npz\")\n",
    "activation_functions = [ReLu, ReLu]\n",
    "\n",
    "input_matrix: np.ndarray = np.array([2, 2])\n",
    "nn.assign_activation_functions(activation_functions)\n",
    "inputs, _ = nn.front_propagation(input_matrix, activation_functions)\n",
    "\n",
    "print(\"Weight array first: \", nn.weights_matrixes[0])\n",
    "print(\"Weight array second: \", nn.weights_matrixes[1])\n",
    "print(\"First input: \", inputs[0][0])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
